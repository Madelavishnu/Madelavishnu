{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0082e487-3cc5-4c79-93a8-103e0364ff34",
   "metadata": {},
   "source": [
    "# MULTIHEAD ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a698c902-c3f2-4c21-bda2-299db5e467d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\anaconda3\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e773e6e-0ba4-45d3-a408-c5d775c23c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e1f4a4b-a6a4-4aad-ba51-bba6a2e83ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1458,  0.5448,  0.3171,  ...,  0.7818, -0.3835, -1.2561],\n",
       "         [-1.3927, -0.5620, -0.4921,  ..., -0.0276,  0.2941, -1.9411],\n",
       "         [ 1.6130, -0.3110,  0.8778,  ...,  1.2637,  0.3617, -1.2672],\n",
       "         [ 0.0891,  0.4357, -0.3769,  ..., -0.7683, -0.5691,  1.0808]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = 4                  # MY NAME IS VISHNU (4 TOKENS)\n",
    "batch_size = 1\n",
    "input_dim = 512                       # FOR EVERY WORD INPUT VECTOR DIM HAS 512\n",
    "d_model = 512                         # OUTPUT OF ATTENTION UNIT\n",
    "x = torch.randn((batch_size, sequence_length, input_dim))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45bd028c-b53e-493a-8d3a-94381971b902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()                              #([1,4,512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "777f1152-62f2-445f-9225-8c1a6259542c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1536, bias=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv_layer = nn.Linear(input_dim, 3 * d_model)\n",
    "qkv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9343f27-d2de-4b25-a62d-9a4014214485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6538,  0.0789,  0.8566,  ...,  0.4444,  0.2386,  0.5976],\n",
       "         [-0.0644,  0.9934, -0.0627,  ..., -0.4559,  0.2525, -0.6323],\n",
       "         [-0.0769, -0.3066,  0.4232,  ...,  0.6009,  0.4618, -0.8853],\n",
       "         [ 0.0464, -0.1677,  0.6598,  ...,  0.6227, -0.2876,  0.3636]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv = qkv_layer(x)\n",
    "qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4bc7522-ef75-4bf1-b404-c4d9ab624003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape                           # ([1,4,1536])          512*3 = 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "984dd77b-0f68-4052-b29a-88b7e962cfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.6538,  0.0789,  0.8566,  ..., -0.6331,  0.6063, -0.7388],\n",
       "          [ 0.0882,  0.0067,  0.2405,  ..., -0.1896,  0.0159,  0.8613],\n",
       "          [-0.0174, -0.9481,  0.4832,  ...,  0.8955, -0.1091, -0.2535],\n",
       "          ...,\n",
       "          [-0.3506,  0.0642, -1.1343,  ..., -0.9535,  0.0884,  0.1644],\n",
       "          [-0.2446, -0.5925,  0.5105,  ..., -0.3860,  0.6691,  0.3578],\n",
       "          [-0.4290,  0.5060,  0.2739,  ...,  0.4444,  0.2386,  0.5976]],\n",
       "\n",
       "         [[-0.0644,  0.9934, -0.0627,  ...,  0.7971,  0.3028, -0.0422],\n",
       "          [ 0.4334, -0.3570,  0.2367,  ..., -0.3192,  0.2682,  1.3620],\n",
       "          [-0.3155, -0.2850, -1.2711,  ...,  0.0703,  0.6375,  0.5030],\n",
       "          ...,\n",
       "          [ 0.3730, -0.4761,  0.6795,  ..., -0.5216, -0.5191,  0.8454],\n",
       "          [-0.1654, -0.7986,  0.4173,  ..., -0.5151,  0.4683, -0.1285],\n",
       "          [-0.7864, -0.0896, -0.6988,  ..., -0.4559,  0.2525, -0.6323]],\n",
       "\n",
       "         [[-0.0769, -0.3066,  0.4232,  ...,  0.6631,  0.9911,  0.5760],\n",
       "          [ 0.4077, -0.8850,  0.4715,  ...,  0.0728,  0.6530,  0.0999],\n",
       "          [ 0.7621,  0.4452,  0.0461,  ..., -0.2362,  0.0661, -0.4968],\n",
       "          ...,\n",
       "          [-0.0208, -0.3309, -0.6180,  ...,  0.7329,  0.5995,  0.2748],\n",
       "          [-0.2503,  1.5118,  0.4256,  ...,  0.6977,  0.3617, -0.4667],\n",
       "          [ 0.0120, -0.5975,  0.2184,  ...,  0.6009,  0.4618, -0.8853]],\n",
       "\n",
       "         [[ 0.0464, -0.1677,  0.6598,  ...,  1.1286,  0.2915,  1.2468],\n",
       "          [-1.0499, -0.0884, -0.3008,  ..., -0.1159,  0.4349, -0.6188],\n",
       "          [-0.1387, -0.4514,  0.1477,  ..., -0.3284,  0.3319,  0.9606],\n",
       "          ...,\n",
       "          [ 0.1269, -0.2615,  0.7092,  ..., -0.0056,  0.3028,  0.5712],\n",
       "          [ 0.8567, -0.0748, -0.2954,  ..., -0.4661,  0.1739,  1.1385],\n",
       "          [-0.6453, -0.2411, -0.4253,  ...,  0.6227, -0.2876,  0.3636]]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_heads = 8\n",
    "head_dim = d_model // num_heads\n",
    "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3 * head_dim)\n",
    "qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a06b090f-8f0e-42a3-950c-abec184a5cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape                         # ([1,4,8,192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c42db0a-5551-4c2d-8429-334e4c0b3a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to perform parellel last 2 operations\n",
    "\n",
    "qkv.permute(0,2,1,3)              # ([batch_size, num_head, sequence_length, 3 * head_dim ])\n",
    "qkv.shape                          # ([1,8,4,192])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79398f45-5199-4530-abe6-056fc78c43e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 8, 64]),\n",
       " torch.Size([1, 4, 8, 64]),\n",
       " torch.Size([1, 4, 8, 64]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunking into a q , k, v\n",
    "\n",
    "q,k,v = qkv.chunk(3, dim= -1)\n",
    "q.shape,k.shape,v.shape        # we get for q k v   ([1,8,4,64])     192/3 = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f36072-9d94-41a3-91de-2a188db82930",
   "metadata": {},
   "source": [
    "## Self Attention for Multiple heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da766473-eaad-4f95-aaf4-3baafd347f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = q.size()[-1]\n",
    "scaled = torch.matmul(q, k.transpose(-2, -1))/ math.sqrt(d_k)       # if q (4*64) k is (64*4)      # these are tensors we cant use k.T\n",
    "scaled.shape                                                            # ([1,8,4,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a5f13-9862-4aab-8492-5fc72f5d2a48",
   "metadata": {},
   "source": [
    "### MASKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "080c71be-bad3-40ea-861b-f6e4156907f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full(scaled.size(), float('-inf'))\n",
    "mask = torch.triu(mask, diagonal=1)                # make upper triangle infinity\n",
    "mask[0][1]                                         #mask for input of single data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0de3a-85a9-475e-bb77-a066047a9e62",
   "metadata": {},
   "source": [
    "(scaled +mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8a6f1f8-0526-4483-9d29-756443ff4c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0035,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [ 0.2269, -0.2004,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [ 0.0602, -0.0716, -0.0345,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [-0.2234, -0.4465, -0.0787,  0.2251,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [ 0.0561, -0.0220, -0.4301,  0.0745,  0.1796,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [-0.5520,  0.2032, -0.0732, -0.4269, -0.4371, -0.1512,    -inf,\n",
       "              -inf],\n",
       "          [ 0.0484,  0.4813, -0.0359,  0.1483,  0.0365, -0.5418,  0.4600,\n",
       "              -inf],\n",
       "          [-0.1119,  0.0035, -0.0086,  0.2691, -0.0194,  0.0714, -0.1101,\n",
       "           -0.0227]],\n",
       "\n",
       "         [[-0.2807,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [-0.1885, -0.1245,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [-0.2620,  0.4379, -0.0949,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [-0.1935, -0.0929, -0.2976, -0.3643,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [-0.0171, -0.1767,  0.1337,  0.4825,  0.2565,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [ 0.0478, -0.3492,  0.0605,  0.1370,  0.0069, -0.6107,    -inf,\n",
       "              -inf],\n",
       "          [-0.3881, -0.3217,  0.2023,  0.0144, -0.1294, -0.3643,  0.4163,\n",
       "              -inf],\n",
       "          [ 0.0453,  0.0823,  0.0560,  0.1307,  0.1147, -0.1470,  0.3474,\n",
       "           -0.2485]],\n",
       "\n",
       "         [[ 0.2558,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [ 0.2385, -0.3242,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [-0.2811, -0.0540,  0.3564,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [-0.7422,  0.2684,  0.2117,  0.0884,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [ 0.0886, -1.1249, -0.0104,  0.0906,  0.3584,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [ 0.4061,  0.3350, -0.1791,  0.0984,  0.8036, -0.1195,    -inf,\n",
       "              -inf],\n",
       "          [-0.1750,  0.0725, -0.3801, -0.0708,  0.2264,  0.2433,  0.2043,\n",
       "              -inf],\n",
       "          [ 0.3616, -0.1760, -0.2400,  0.4051,  0.7806,  0.2233, -0.3022,\n",
       "           -0.0868]],\n",
       "\n",
       "         [[ 0.2723,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [-0.5641, -0.4948,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [ 0.0474, -0.0417, -0.1645,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [-0.6558,  0.0785, -0.0058, -0.1024,    -inf,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [ 0.0260, -0.0307,  0.7756,  0.0368, -0.2737,    -inf,    -inf,\n",
       "              -inf],\n",
       "          [-0.3964, -0.4518, -0.1510,  0.5913, -0.1481, -0.1536,    -inf,\n",
       "              -inf],\n",
       "          [ 0.0117, -0.0557,  0.4721, -0.0885,  0.3543, -0.0035,  0.1277,\n",
       "              -inf],\n",
       "          [-0.4220,  0.2158, -0.2715, -0.1217, -0.2082,  0.3275,  0.0926,\n",
       "            0.1592]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = scaled + mask                         # help us to understand the words \n",
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58f8fe76-960f-4438-a604-eb54de7c2f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = F.softmax(scaled, dim = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8d21351-43f6-4e20-9d7f-f11b5bd4f5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.6052, 0.3948, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3589, 0.3146, 0.3265, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2212, 0.1769, 0.2556, 0.3463, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2132, 0.1972, 0.1311, 0.2172, 0.2413, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1178, 0.2506, 0.1901, 0.1335, 0.1321, 0.1759, 0.0000, 0.0000],\n",
       "        [0.1313, 0.2024, 0.1207, 0.1451, 0.1297, 0.0728, 0.1981, 0.0000],\n",
       "        [0.1100, 0.1235, 0.1220, 0.1611, 0.1207, 0.1322, 0.1102, 0.1203]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]                         # make upper triangle with zero now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92c69640-ee03-44e8-8dd7-2e244d8ce6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 64])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.matmul(attention, v)\n",
    "values.shape                                #([1,8,4,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b204a68-17fe-4616-a9b8-0bd2544db105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a functiom for this , we dont know we are dealing with encoder or decoder\n",
    "\n",
    "import math\n",
    "\n",
    "def scaled_dot_product(q,k,v, mask = None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1,-2)) /math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled =scaled + mask\n",
    "    attention = F.softmax(scaled, dim = -1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bd83694-445c-453f-a8bc-8b2dc7629d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "values, attention = scaled_dot_product(q, k, v, mask = mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c39d0c81-d4c3-4187-8c2c-a741cffdbdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6052, 0.3948, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3589, 0.3146, 0.3265, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2212, 0.1769, 0.2556, 0.3463, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2132, 0.1972, 0.1311, 0.2172, 0.2413, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1178, 0.2506, 0.1901, 0.1335, 0.1321, 0.1759, 0.0000, 0.0000],\n",
      "        [0.1313, 0.2024, 0.1207, 0.1451, 0.1297, 0.0728, 0.1981, 0.0000],\n",
      "        [0.1100, 0.1235, 0.1220, 0.1611, 0.1207, 0.1322, 0.1102, 0.1203]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 64])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape                  #([1,8,4,4])\n",
    "print(attention[0][0])\n",
    "values.size()                     #([1,8,4,64])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd9bb727-7f51-42fc-9b32-c36e083ad9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets concat each heads \n",
    "\n",
    "values = values.reshape(batch_size, sequence_length, num_heads * head_dim)\n",
    "values.size()                                    #([1,4,512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4220013-41af-4c90-b0a6-452ce17e97dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for communction eachother to share information create NN\n",
    "linear_layer = nn.Linear(d_model, d_model)             #(512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12219b33-9398-4538-934f-7810a0d7d81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = linear_layer(values)\n",
    "out.shape                                      # ([1,4,512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f42fee-b680-462a-9990-5280c9575d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create all in one set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5edbedb-aa92-451e-b016-837969cdcb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size():torch.Size([30, 5, 512])\n",
      "qkv.size(): torch.Size([30, 5, 1536])\n",
      "qkv.size(): torch.Size([30, 5, 8, 192])\n",
      "qkv.size(): torch.Size([30, 8, 5, 192])\n",
      "q size torch.Size([30, 8, 5, 64])\n",
      "k size torch.Size([30, 8, 5, 64])\n",
      "v size torch.Size([30, 8, 5, 64])\n",
      "values size torch.Size([30, 8, 5, 64])\n",
      "attention.size torch.Size([30, 8, 5, 5])\n",
      "values size torch.Size([30, 5, 512])\n",
      "out size torch.Size([30, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "def scaled_dot_product(q,k,v, mask = None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1,-2)) /math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled =scaled + mask\n",
    "    attention = F.softmax(scaled, dim = -1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim, 3*d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        batch_size ,sequence_length, input_dim = x.size()\n",
    "        print(f\"x.size():{x.size()}\")\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3* self.head_dim)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.permute(0,2,1,3)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        q, k, v = qkv.chunk(3, dim = -1)\n",
    "        print(f\"q size {q.size()}\\nk size {k.size()}\\nv size {v.size()}\")\n",
    "\n",
    "\n",
    "        values , attention = scaled_dot_product(q, k, v, mask)\n",
    "        print(f\"values size {values.size()}\\nattention.size {attention.size()}\")\n",
    "        values = values.reshape(batch_size, seq_len, self.num_heads * self.head_dim)\n",
    "        print(f\"values size {values.size()}\")\n",
    "        out = self.linear_layer(values)\n",
    "        print(f\"out size {out.size()}\")\n",
    "\n",
    "        return out\n",
    "\n",
    "input_dim = 512\n",
    "d_model = 512\n",
    "num_heads= 8\n",
    "\n",
    "batch_size = 30\n",
    "seq_len= 5\n",
    "x = torch.randn((batch_size, seq_len, input_dim))\n",
    "\n",
    "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
    "out = model.forward(x)    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff916f87-51fe-4920-8a05-587ab2b8c152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257eb794-bbb8-441a-b989-086412415fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eeb9020f-f50c-4668-9406-00c6fc20e777",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac62b1-4d19-4859-97b9-295b8a3cd041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
